import torch
import torch.nn.functional as F
import torch.fft

def fft_convolve(image, kernel):
    ih, iw = image.shape
    kh, kw = kernel.shape

    assert(image.shape[0] >= kernel.shape[0])
    assert(image.shape[1] >= kernel.shape[1])

    kernel = F.pad(kernel, (0, iw - kw, 0, ih - kh))

    x = torch.fft.rfftn(image)
    y = torch.fft.rfftn(kernel)
    z = x * y
    z = torch.fft.irfftn(z, s=(ih, iw))
    z = z[kh - 1:, kw - 1:]
    z = z[:ih - kh + 1, :iw - kw + 1]
    return z

device = torch.device("cuda")

class Model(torch.nn.Module):
    def __init__(self, psf_radius):
        psf_size = 2 * psf_radius + 1

        psf = torch.ones((psf_size, psf_size), device=device) / psf_size**2

        offset = torch.tensor([0.33], device=device)

        # good initialization is very critical
        M = torch.tensor([
            [1., 0, 0.003, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 1., 0.015, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            #[1, 0, 0.001, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            #[0, 1, 0.01, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            #[ 1.0338e+00,  5.0464e-04,  4.0651e-03, -1.3710e-02,  2.0760e-03, 4.6248e-03, -3.9795e-02,  5.7094e-03, -3.4138e-02, -3.0661e-03],
            #[-4.8500e-03,  1.0225e+00, -6.8927e-04, -1.1893e-02, -6.2366e-03, 1.7069e-02,  9.9226e-03, -2.2422e-02, -2.4511e-03, -1.1349e-02],
        ], device=device)

        #background = torch.full((10, 10), fill_value=0.33, device=device)

        params = [psf, offset, M]

        for param in params:
            param.requires_grad = True

        self.psf_radius = psf_radius
        self.params = params
        self.psf = psf
        self.M = M
        self.offset = offset

    def __call__(self, cam1, noise=0.0):
        # noise = 0.03 looks reasonable
        h, w = cam1.shape

        x = torch.linspace(-1, 1, w, device=device)
        y = torch.linspace(-1, 1, h, device=device)
        y, x = torch.meshgrid(y, x)

        features = [x, y, 1, x*x, x*y, y*y, x*x*x, x*x*y, x*y*y, y*y*y]

        x_warped = sum(weight * feature for weight, feature in zip(self.M[0], features))
        y_warped = sum(weight * feature for weight, feature in zip(self.M[1], features))

        grid = torch.stack([x_warped, y_warped], dim=2)

        warped_cam1 = F.grid_sample(
            cam1[None, None, :, :],
            grid[None, :, :, :],
            mode='bicubic',
            align_corners=True,
            padding_mode='border')[0, 0, :, :]

        convolved_warped_cam1 = fft_convolve(warped_cam1, self.psf) + self.offset
        #convolved_warped_cam1 += resize(background, convolved_warped_cam1.shape)

        if noise != 0.0:
            convolved_warped_cam1 += noise * torch.randn(convolved_warped_cam1.shape, device=device)

        return convolved_warped_cam1

    def loss(self, cam1, cam2):
        psf = self.psf
        psf_radius = self.psf_radius

        cam1_transformed = self(cam1)
        cam2_cropped = cam2[psf_radius:-psf_radius, psf_radius:-psf_radius]

        difference = cam1_transformed - cam2_cropped

        mse = torch.mean(torch.square(difference))

        psf_regularization = torch.mean(torch.abs(psf))

        flipped_psf0 = torch.flip(self.psf, [0])
        flipped_psf1 = torch.flip(self.psf, [1])

        loss = mse + 10 * psf_regularization

        return loss, mse, difference, cam1_transformed, cam2_cropped

from PIL import Image
import numpy as np
import os, time, json, random
import matplotlib.pyplot as plt
import scipy.optimize

def load(step, cam, sample, font):
    fix_for_inconsistent_naming_scheme = {
        "Times": "timesR",
        "Verdana": "verdanaRef",
    }[font]

    path = f"~/data/hdc2021/step{step}/{font}/CAM{cam:02d}/focusStep_{step}_{fix_for_inconsistent_naming_scheme}_size_30_sample_{sample:04d}.tif"
    path = os.path.expanduser(path)

    image = Image.open(path)

    image = np.float32(image) / 65535.0

    return image

result = scipy.optimize

step = 0
sample = 2

def get_warping_matrix(step):
    if step == 0: return [1.0074838399887085, 0.0007350334199145436, 0.0018522378522902727, 0.0011821923544630408, -9.216999023919925e-05, -2.1575890059466474e-05, -0.0008361316868104041, -2.0978655811632052e-05, 2.024814057222102e-05, -9.610102279111743e-05, 0.005001508630812168, 1.0126982927322388, -0.002687784843146801, 0.0004823343479074538, -0.0003023565514013171, -0.00017967041640076786, 5.8112331316806376e-05, 0.0004127228748984635, -0.00010364824265707284, -3.341829142300412e-05, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
    if step == 1: return [1.0001074075698853, 0.00026503356639295816, 0.0014267113292589784, -0.000140930904308334, -0.00024006569583434612, -0.002316687721759081, -8.164918835973367e-05, 0.00024537910940125585, 0.0002223470073658973, 0.0020410853903740644, 0.005251534283161163, 1.0058963298797607, -0.004370789974927902, -0.000786478107329458, 0.00014022525283508003, -0.0018259487114846706, -0.0007027303799986839, 0.002358881291002035, -0.00045202276669442654, -0.004688096232712269, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
    if step == 2: return [0.9938850998878479, 0.0011783745139837265, 0.0, 0.001726538990624249, 0.00071810552617535, -0.0006797484820708632, -0.0037932987324893475, -0.00037118676118552685, -0.0031556240282952785, -0.003694966435432434, 0.005031114909797907, 1.0014299154281616, -0.00625627301633358, -0.0025116801261901855, 0.00016182185208890587, -0.007379685062915087, -0.0018687976989895105, 0.002322555286809802, 0.005523629952222109, -0.029866278171539307, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
    if step == 3: return [0.9869324564933777, 0.00224688439629972, -0.0008935428340919316, 0.002959209494292736, -0.0022612223401665688, 0.0018939843866974115, -0.004060809034854174, 0.0017625142354518175, -0.006656560115516186, -0.009651963599026203, 0.00016188605513889343, 1.0035479068756104, -0.010218928568065166, 0.0005651656538248062, -0.0009788924362510443, 0.0014329419936984777, 0.008163115940988064, 0.005938321352005005, 0.008032983168959618, -0.08853603154420853, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
    if step == 4: return [0.983738362789154, 0.0023218116257339716, -0.0017126877792179585, 0.001369951176457107, -0.004269269295036793, 0.004380248486995697, -0.016033707186579704, 0.0067543284967541695, -0.016424868255853653, -0.01624421216547489, 7.708399789407849e-05, 0.994385302066803, -0.012866039760410786, -0.001022055745124817, 0.0037307552993297577, 0.0027339875232428312, 0.009606639854609966, -0.008584169670939445, 0.013230630196630955, -0.09363924711942673, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
    if step == 5: return [0.9786288738250732, 0.003588682971894741, -0.0023918221704661846, 0.004777341615408659, -0.0037737672682851553, 0.002030150732025504, -0.013176627457141876, -0.010321627371013165, -0.026121007278561592, -0.015811236575245857, 0.001201795064844191, 1.0035192966461182, -0.01841144822537899, 0.008479919284582138, 0.003908892627805471, 0.0044402433559298515, 0.015674248337745667, 0.005413076840341091, 0.008270949125289917, -0.18248037993907928, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
    if step >= 6: return [0.9777207374572754, 0.003674966050311923, -0.000865395471919328, 0.00839876476675272, -0.00921174418181181, -0.00444203382357955, -0.024727338925004005, -0.007308421190828085, -0.05595914274454117, -0.009856735356152058, -0.0010057302424684167, 1.0023410320281982, -0.01852775737643242, 0.0016161234816536307, -0.0016956499312072992, 0.002951698610559106, 0.026358529925346375, -0.017851702868938446, -0.004329687915742397, -0.18836215138435364, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]

sharp = load(step=step, cam=1, sample=sample, font="Times")
blurry = load(step=step, cam=2, sample=sample, font="Times")

sharp = torch.tensor(sharp, device=device)
blurry = torch.tensor(blurry, device=device)

def predict(params):
    #M = params.reshape(3, 3)
    M = params.reshape(10, 10)

    h, w = blurry.shape

    x = torch.linspace(-1, 1, w, device=device)
    y = torch.linspace(-1, 1, h, device=device)
    y, x = torch.meshgrid(y, x)

    features = [x, y, 1, x*x, x*y, y*y, x*x*x, x*x*y, x*y*y, y*y*y]

    x_warped = sum(weight * feature for weight, feature in zip(M[0], features))
    y_warped = sum(weight * feature for weight, feature in zip(M[1], features))

    grid = torch.stack([x_warped, y_warped], dim=2)

    blurry_dewarped = F.grid_sample(
        blurry[None, None, :, :],
        grid[None, :, :, :],
        mode='bicubic',
        align_corners=True,
        padding_mode='border')[0, 0, :, :]

    return blurry_dewarped

def loss(params):
    blurry_dewarped = predict(params)

    blurry_dewarped_centered = blurry_dewarped - blurry_dewarped.mean()

    sharp_centered = sharp - sharp.mean()

    return torch.mean(torch.square(blurry_dewarped_centered - sharp_centered))

#result = torch.eye(3, device=device).ravel()
result = torch.eye(10, device=device).ravel()
#result = get_warping_matrix(step)

#result = [0.9786176681518555, 9.498788858763874e-05, -0.0011383077362552285, 0.003317170077934861, 0.9763563871383667, -0.012626998126506805, 0.0, 0.0, 1.0]
#result = [0.983738362789154, 0.0023218116257339716, -0.0017126877792179585, 0.001369951176457107, -0.004269269295036793, 0.004380248486995697, -0.016033707186579704, 0.0067543284967541695, -0.016424868255853653, -0.01624421216547489, 7.708399789407849e-05, 0.994385302066803, -0.012866039760410786, -0.001022055745124817, 0.0037307552993297577, 0.0027339875232428312, 0.009606639854609966, -0.008584169670939445, 0.013230630196630955, -0.09363924711942673, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
#result =  [0.9786288738250732, 0.003588682971894741, -0.0023918221704661846, 0.004777341615408659, -0.0037737672682851553, 0.002030150732025504, -0.013176627457141876, -0.010321627371013165, -0.026121007278561592, -0.015811236575245857, 0.001201795064844191, 1.0035192966461182, -0.01841144822537899, 0.008479919284582138, 0.003908892627805471, 0.0044402433559298515, 0.015674248337745667, 0.005413076840341091, 0.008270949125289917, -0.18248037993907928, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
#result =  [0.9777207374572754, 0.003674966050311923, -0.000865395471919328, 0.00839876476675272, -0.00921174418181181, -0.00444203382357955, -0.024727338925004005, -0.007308421190828085, -0.05595914274454117, -0.009856735356152058, -0.0010057302424684167, 1.0023410320281982, -0.01852775737643242, 0.0016161234816536307, -0.0016956499312072992, 0.002951698610559106, 0.026358529925346375, -0.017851702868938446, -0.004329687915742397, -0.18836215138435364, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
result = torch.tensor(result, device=device)

if 1:
    with torch.no_grad():
        min_loss = loss(result)

    #deltas = np.float64([0.001, 0.001, 0.1, 0.001, 0.001, 0.1])
    deltas = [
        0.001, 0.001, 0.1, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,
        0.001, 0.001, 0.1, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,
    ]

    """
    # update this a few times manually or increase iteration
    # step 4
    result = [1.0219102499631356, -0.0016858373016614507, -23.331516647622866, -0.0033, 1.0234880235892758, -3.699781371238554, 0.0, 0.0, 1.0]
    # step 5
    result = [1.02776082759815, -0.0020003510134727794, -29.55097619101832, -0.004190131656433443, 1.0350230381334986, -7.822552208652559, 0.0, 0.0, 1.0]
    # step 7
    result =  [1.045, -0.02051229831530518, -30.90508138855091, -0.00355119449929428, 1.0457119385521685, -12.677377066864135, 0.0, 0.0, 1.0]
    #result = [1.0538820236617994, -0.018957636467547733, -67.37464728925355, -0.0023941798962394427, 1.047195087669039, -15.424603264508542, 0.0, 0.0, 1.0]
    """

with torch.no_grad():
    for iteration in range(100):
        scale = np.random.randn()
        for rate in [0.033, 0.1, 0.33, 1.0, 3.3, 10]:
            for i in range(len(deltas)):
                for direction in [-1, 1]:
                    new_result = result.clone()

                    new_result[i] += rate * direction * deltas[i] * scale

                    new_loss = loss(new_result)

                    if new_loss < min_loss:
                        min_loss = new_loss
                        result = new_result
                        print(min_loss, iteration, list(map(float, result)))

    blurry_dewarped = predict(result)

    gamma = 3.3
    sharp = sharp**gamma
    blurry_dewarped = blurry_dewarped**gamma
    preview = torch.clip(sharp - blurry_dewarped, 0, 1)
    preview = preview**(1/gamma)

    plt.imshow(preview.cpu(), cmap='gray', vmin=0, vmax=1)
    plt.show()

